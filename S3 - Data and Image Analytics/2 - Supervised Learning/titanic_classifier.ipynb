{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8a4bef4d",
   "metadata": {},
   "source": [
    "# **Titanic Classifier - Report**\n",
    "\n",
    "#### ***Introduction to the report***\n",
    "The sinking of the Titanic is one of the most infamous shipwrecks in history. On April 15, 1912, during her maiden voyage, the widely considered “unsinkable” RMS Titanic sank after colliding with an iceberg. Unfortunately, there weren’t enough lifeboats for everyone onboard, resulting in the death of 1502 out of 2224 passengers and crew.\n",
    "\n",
    "In this report we will attempt to answer the question \"what sorts of people were more likely to survive?\" using 3 different machine learning approaches.<br><br>\n",
    "We decided to use the KNN approach, logistic regression and trees."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "558646be",
   "metadata": {},
   "source": [
    "*DICLAIMER: The number of comments inside of the actual code is kept to a minimum due to this being a report.*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9129e095",
   "metadata": {},
   "source": [
    "Created by **Ron Ismaili** and **Alberto Gamez Gonzalez**."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "00bf7de4",
   "metadata": {},
   "source": [
    "#### ***First look at the dataset***\n",
    "\n",
    "We start off by importing all of the libraries necessary to run our code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b846355-c372-4321-ae0d-a7f5b2866621",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5fdba520",
   "metadata": {},
   "source": [
    "We follow up by loading in the dataset *'titanic_train.csv'* into our file and then taking a look at the **dataframe**, its **shape** as well as its **keys**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf8fd992-3d59-43f1-84ff-0bc19cc5ba4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('titanic_train.csv')\n",
    "display(df)\n",
    "print(\"Data Shape:\", df.shape)\n",
    "print(\"Data Keys:\\n\", df.keys())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dc0a2d95",
   "metadata": {},
   "source": [
    "#### ***General dataset information***\n",
    "\n",
    "In the above section, we can see that our dataset contains **1047 rows** x **14 columns**, meaning that for each of the passengers *(of which there are 1047)* we have **14** features each.<br>\n",
    "The following is a list of all the available features in this dataset as well as their details:<br>\n",
    "1.  **PClass** - *(Passenger class)* - as a means to identify the SES *(Socio-economic status)* of the passenger. *(1 - upper, 2 - middle, 3 - lower)*\n",
    "2.  **Survived** - Survival status of the passenger. *(Has the passenger survived the tragedy)*\n",
    "3.  **Name** - Full name of the passenger.\n",
    "4.  **Sex** - Gender of the passenger.\n",
    "5.  **Age** - Age of the passenger. *(In years)*\n",
    "6.  **Sibsp** - Number of siblings / spouses aboard the Titanic.\n",
    "7.  **Parch** - Number of parents / children aboard the Titanic.\n",
    "8.  **Ticket** - Ticket number.\n",
    "9.  **Fare** - Passenger fare. *(Amount paid for the ticket)*\n",
    "10.  **Cabin** - Cabin number.\n",
    "11.  **Embarked** - Port from where the ship embarked. *(C = Cherbourg, Q = Queenstown, S = Southampton)*\n",
    "12.  **Boat** - How many boats have been used.\n",
    "13.  **Body** - Has the body been found or not.\n",
    "14.  **Homedest** - Where the passenger's homedestination is."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cf665c1e",
   "metadata": {},
   "source": [
    "#### ***Data pre-processing***\n",
    "\n",
    "Before we get started with anything, we have to look at our data with an extra pair of glasses and look for missing data, strings that need to be converted, etc.<br><br>\n",
    "The first thing that jumped at us when we saw the data was that there was plenty of missing data in the dataset. As an example lets look at the **age** feature:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a47a6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"age\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9a5a6734",
   "metadata": {},
   "source": [
    "As we can see, there are plenty of **\"?\"** within this column. The **\"?\"** in this case means **missing data**. But there isn't missing data only in the age column, but in others too. Now we need to start cleaning the useless and uncleaned data.<br>\n",
    "\n",
    "We will start off by dealing with the missing data in our dataset.<br>\n",
    "To locate the missing DATA there are multiple methods:\n",
    "- **Heat maps**\n",
    "- **Percentages**\n",
    "- **Bar graphs**\n",
    "\n",
    "In our case we think that **percentages** are the most convinient for finding out how much missing data there is in each of the columns."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c35f8c9d",
   "metadata": {},
   "source": [
    "We define and run the function for calculating the missing % of data in all of the columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff29340-1b00-4771-901d-265e68538b45",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def missingPercentages(self , str = \"\"):\n",
    "    for col in self.columns:\n",
    "        pct_missing = np.mean(df[col] == str)\n",
    "        print('{} - {}%'.format(col, round(pct_missing*100)))\n",
    "\n",
    "missingPercentages(df , \"?\") # Function which uses the dataframe and looks for percentages of missing data \"?\"."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ebff6c8b",
   "metadata": {},
   "source": [
    "Here we can see the % of missing data in each column.<br><br>\n",
    "\n",
    "There are **5 features** with missing data:\n",
    "- **Age**\n",
    "- **Cabin**\n",
    "- **Boat**\n",
    "- **Body**\n",
    "- **Homedest**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8fc68421",
   "metadata": {},
   "source": [
    "Now we will define some functions to clean the dataset, remove unnecessary data as well as deal with the missing data problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "757b9aa6-7ec1-40bd-a5e9-08f1019a02c4",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def embarkedData(input_data): # We need to change the embarked port format.\n",
    "    if (input_data == \"C\"):\n",
    "        return 1\n",
    "    elif (input_data == \"Q\"):\n",
    "        return 2\n",
    "    else:\n",
    "        return 3\n",
    "\n",
    "def reconstructSex(sex_string): # We need to change the male and female format.\n",
    "    if (sex_string == 'male'):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def cleanData(data_input, restriction = \"?\" , datasub = 0): # We substitute the missing data in the dataset with 0s.\n",
    "    if (data_input == restriction):\n",
    "        return datasub\n",
    "    else:\n",
    "        return data_input\n",
    "        \n",
    "def cleanDataString(data_input, restriction = \"?\" , datasub = 0): # We substitute the missing data in the dataset with 0s.\n",
    "    if ((type(data_input) == str ) or (data_input == restriction)):\n",
    "        return datasub\n",
    "    else:\n",
    "        return data_input"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5717aadd",
   "metadata": {},
   "source": [
    "We will now apply all of the necessary functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a7da22-bca0-4ef1-987f-82997de129af",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# We change the format of \"Sex\" and \"Embarked\" so that the algorithm can understand it.\n",
    "df[\"sex\"] = df[\"sex\"].apply(reconstructSex)\n",
    "df[\"embarked\"] = df[\"embarked\"].apply(embarkedData)\n",
    "\n",
    "# We deal with the missing data in \"Age\", \"Cabin\", \"Fare\", \"Body\" and \"Ticket\".\n",
    "df[\"age\"] = df[\"age\"].apply(cleanData)\n",
    "\n",
    "df[\"cabin\"] = df[\"cabin\"].apply(cleanData) \n",
    "\n",
    "df[\"fare\"] = df[\"fare\"].apply(cleanData)\n",
    "df[\"fare\"] = df[\"fare\"].apply(float)\n",
    "\n",
    "df[\"body\"] = df[\"body\"].apply(cleanData)  \n",
    "for i,value in enumerate(df[\"boat\"]):\n",
    "    try:\n",
    "        df[\"boat\"][i] = int(df[\"boat\"][i])\n",
    "    except:\n",
    "        df[\"boat\"][i] = cleanDataString(df[\"boat\"][i])\n",
    "\n",
    "df[\"ticket\"] = df[\"ticket\"].apply(cleanData)  \n",
    "for i,value in enumerate(df[\"boat\"]):\n",
    "    try:\n",
    "        df[\"ticket\"][i] = int(df[\"ticket\"][i])\n",
    "    except:\n",
    "        df[\"ticket\"][i] = cleanDataString(df[\"ticket\"][i])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "84d53980",
   "metadata": {},
   "source": [
    "Lets now take a look at the final result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c47e611-8e0f-49d0-a675-ecd299ec71f2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "display(df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "de345ad9",
   "metadata": {},
   "source": [
    "As we can see, all of the data is now neat and clean, ready to be analyzed."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f56bf333",
   "metadata": {},
   "source": [
    "#### ***Exploratory Data Analysis (EDA)***\n",
    "\n",
    "Now that everything is said and done, and we finally have our dataset ready to go, it's time to take a deep dive into the data and analyze it. It is our job now to look at these traits and decide which ones are more important than the others and if we can create any new features ourselves *(feature engineering)*.<br>\n",
    "\n",
    "For starters, we know that the Titanic incident happened on **April 15, 1912**. We have to keep in mind the date all of this happened when taking into consideration the data.<br>\n",
    "The Titanic had **2224** individuals on board, out of which **1502** died due to the incident, giving us a roughly **67.53%** death rate, or inversely a roughly **32.47%** survival rate. We believe that there is a reason why certain people survived and others did not.<br><br>\n",
    "\n",
    "The first thing that came to mind was **gender**. We think that gender played a huge role on the survival chances of a person. We believe that males were more likely to survive compared to females due to their biological differences. Males are built differently biologically speaking, and when it comes to surviving in the deep blue sea, we are of the opinion that males have an edge over females.<br><br>\n",
    "\n",
    "Another very important feature in our opinion is the **Socio-Economic Status** *(SES)* of the passenger. We believe that if a passenger had a higher **SES**, their chances of survival would be higher due to multiple factors. They probably had better access to life boats, they probably had better quality of food and an overall better experience on the boat. Whereas those with very low **SES** would stay in very poor conditions within the Titanic. All of this could contribute to the survival chances of the passengers.<br><br> \n",
    "\n",
    "**Safety boats** also played a huge role in the survival chances of an individual. If there were more safety boats, the chances up survival would go up.<br><br>\n",
    "\n",
    "We experimented with **\"body\"** in our model and found out that it also played an important role in determining if an individual would survive or not. We are unsure as to why but figured that it would be important to note down here.<br><br>\n",
    "\n",
    "*We also played with many other features in many different combinations but we found that these 5 are the most effective at predicting the survival chances of a passenger.*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "18be4983",
   "metadata": {},
   "source": [
    "#### ***Preparing and testing the algorithms***\n",
    "First we prepare all of our necessary features into one spot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7b0c49-f9a5-426c-895d-11e08b175038",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "criterios_np = df[['pclass','sex','boat','body','embarked']].to_numpy() # We gather all of the most important features here.\n",
    "survived_np = df.survived.to_numpy() # Change the format to numpy. Therefore we can use numpy libraries and avoid errors."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6a1cd94d",
   "metadata": {},
   "source": [
    "Then we prepare the training sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad5c08a-8b74-4347-b1d3-ee4648d3dbdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X1_train, X1_test, y1_train, y1_test = train_test_split(\n",
    "    criterios_np , survived_np , random_state=0)\n",
    "\n",
    "X2_train, X2_test, y2_train, y2_test = train_test_split(\n",
    "    criterios_np, survived_np, random_state=42)\n",
    "\n",
    "X3_train, X3_test, y3_train, y3_test = train_test_split(\n",
    "    criterios_np, survived_np, random_state=42)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2a683192",
   "metadata": {},
   "source": [
    "Then we do the fitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "398a7507",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=6)\n",
    "knn.fit(X1_train , y1_train)\n",
    "\n",
    "logreg = LogisticRegression().fit(X2_train, y2_train)\n",
    "\n",
    "tree = DecisionTreeClassifier(random_state=0)\n",
    "tree.fit(X3_train, y3_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "620ea7e1",
   "metadata": {},
   "source": [
    "***The KNN algorithm:***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2000bef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"KNN algorithm:\")\n",
    "print(\"Training set score: {:.2f}\".format(knn.score(X1_train, y1_train)))\n",
    "print(\"Test set score: {:.2f}\".format(knn.score(X1_test, y1_test)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fa5a2208",
   "metadata": {},
   "source": [
    "***The Logistic regression algorithm:***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d725d5ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Logicistic regression algorithm:\")\n",
    "print(\"Training set score: {:.3f}\".format(logreg.score(X2_train, y2_train)))\n",
    "print(\"Test set score: {:.3f}\".format(logreg.score(X2_test, y2_test)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a46a2025",
   "metadata": {},
   "source": [
    "***The tree algorithm:***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d5be43f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Tree algorithm:\")\n",
    "print(\"Training set score: {:.2f}\".format(knn.score(X3_train, y3_train)))\n",
    "print(\"Test set score: {:.2f}\".format(knn.score(X3_test, y3_test)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0434f26a",
   "metadata": {},
   "source": [
    "#### ***Conclusion***\n",
    "\n",
    "The ranking of our 3 algorithms is as follows:\n",
    "1. Tree algorithm - **0.94**\n",
    "2. Logistic regression algorithm - **0.927**\n",
    "3. KNN algorithm - **0.91**\n",
    "\n",
    "**Tree algorithm** - This algorithm performed the best, it not only had the best score, but it also generalized the best out of the three.<br>\n",
    "**Logistic regression algorithm** - This algorithm performed the second best, generalizing relatively well.<br>\n",
    "**KNN algorithm** - This algorithm performed the worst *(although still a respectable 0.91)*, it not only had the worst score, but it also generalized the worst out of the three, meaning there was some overfitting.<br>\n",
    "\n",
    "*We have learned a lot during this project and we would have done many things much differently now that we have some more experience. It was fun and a bit challenging, we hope you enjoyed the report.*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "7037ec6d02548fe664234522c81660db3b8126c71ab2fbe7c19beb643581e16e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
